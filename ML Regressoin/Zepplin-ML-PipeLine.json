{"paragraphs":[{"text":"import org.apache.spark.SparkContext\r\nimport org.apache.spark.SparkConf\r\nimport scala.io.Source\r\nimport org.apache.spark.mllib.regression.LabeledPoint\r\nimport org.apache.spark.mllib.linalg.Vectors\r\nimport org.apache.spark.mllib.stat.{MultivariateStatisticalSummary, Statistics}\r\nimport org.apache.spark.mllib.feature.{StandardScaler,Normalizer,ChiSqSelector}\r\nimport org.apache.spark.mllib.evaluation.{MulticlassMetrics, BinaryClassificationMetrics}\r\nimport org.apache.spark.sql.{Row, SQLContext}\r\nimport org.apache.spark.ml.classification.{LogisticRegression, OneVsRest}\r\nimport sqlContext.implicits._\r\nimport org.apache.spark.rdd.PairRDDFunctions\r\nimport org.apache.spark.mllib.linalg.Matrix\r\nimport org.apache.spark.mllib.linalg.distributed.RowMatrix\r\nimport org.apache.spark.mllib.linalg.SingularValueDecomposition\r\nimport org.apache.spark.mllib.feature.PCA\r\nimport org.apache.spark.ml.{Pipeline, PipelineStage, Transformer}\r\nimport org.apache.spark.ml.tuning.{ParamGridBuilder, CrossValidator}\r\nimport org.apache.spark.ml.classification.{DecisionTreeClassificationModel, DecisionTreeClassifier}\r\nimport org.apache.spark.ml.regression.LinearRegression \r\nimport org.apache.spark.ml.util.MetadataUtils\r\nimport org.apache.spark.ml.evaluation.{BinaryClassificationEvaluator, RegressionEvaluator}\r\nimport org.apache.spark.mllib.evaluation.{RegressionMetrics, MulticlassMetrics}\r\nimport org.apache.spark.rdd.RDD\r\nimport org.apache.spark.sql.types.StringType\r\nimport org.apache.spark.sql.{SQLContext, DataFrame}","dateUpdated":"Apr 19, 2016 6:08:29 PM","config":{"colWidth":12,"editorMode":"ace/mode/scala","graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1460937586538_485155020","id":"20160417-195946_1263788677","result":{"code":"SUCCESS","type":"TEXT","msg":"import org.apache.spark.SparkContext\nimport org.apache.spark.SparkConf\nimport scala.io.Source\nimport org.apache.spark.mllib.regression.LabeledPoint\nimport org.apache.spark.mllib.linalg.Vectors\nimport org.apache.spark.mllib.stat.{MultivariateStatisticalSummary, Statistics}\nimport org.apache.spark.mllib.feature.{StandardScaler, Normalizer, ChiSqSelector}\nimport org.apache.spark.mllib.evaluation.{MulticlassMetrics, BinaryClassificationMetrics}\nimport org.apache.spark.sql.{Row, SQLContext}\nimport org.apache.spark.ml.classification.{LogisticRegression, OneVsRest}\nimport sqlContext.implicits._\nimport org.apache.spark.rdd.PairRDDFunctions\nimport org.apache.spark.mllib.linalg.Matrix\nimport org.apache.spark.mllib.linalg.distributed.RowMatrix\nimport org.apache.spark.mllib.linalg.SingularValueDecomposition\nimport org.apache.spark.mllib.feature.PCA\nimport org.apache.spark.ml.{Pipeline, PipelineStage, Transformer}\nimport org.apache.spark.ml.tuning.{ParamGridBuilder, CrossValidator}\nimport org.apache.spark.ml.classification.{DecisionTreeClassificationModel, DecisionTreeClassifier}\nimport org.apache.spark.ml.regression.LinearRegression\nimport org.apache.spark.ml.util.MetadataUtils\nimport org.apache.spark.ml.evaluation.{BinaryClassificationEvaluator, RegressionEvaluator}\nimport org.apache.spark.mllib.evaluation.{RegressionMetrics, MulticlassMetrics}\nimport org.apache.spark.rdd.RDD\nimport org.apache.spark.sql.types.StringType\nimport org.apache.spark.sql.{SQLContext, DataFrame}\n"},"dateCreated":"Apr 17, 2016 7:59:46 PM","dateStarted":"Apr 19, 2016 6:08:29 PM","dateFinished":"Apr 19, 2016 6:09:00 PM","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:28"},{"text":"val inputFileValue = z.input(\"File Name\")","dateUpdated":"Apr 19, 2016 6:09:40 PM","config":{"colWidth":12,"editorMode":"ace/mode/scala","graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true},"settings":{"params":{"File Name":"/Users/rachanrhegde/BigData_FinalProject/S3/S3_data/out/pipelineTest.txt"},"forms":{"File Name":{"name":"File Name","displayName":"File Name","defaultValue":"","hidden":false}}},"jobName":"paragraph_1460937586539_484770271","id":"20160417-195946_1673753703","result":{"code":"SUCCESS","type":"TEXT","msg":"inputFileValue: Object = /Users/rachanrhegde/BigData_FinalProject/S3/S3_data/out/pipelineTest.txt\n"},"dateCreated":"Apr 17, 2016 7:59:46 PM","dateStarted":"Apr 19, 2016 6:09:40 PM","dateFinished":"Apr 19, 2016 6:09:41 PM","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:29"},{"text":"val data = sc.textFile(inputFileValue.toString)","dateUpdated":"Apr 17, 2016 7:59:46 PM","config":{"colWidth":12,"editorMode":"ace/mode/scala","graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1460937586539_484770271","id":"20160417-195946_1903688261","result":{"code":"SUCCESS","type":"TEXT","msg":"data: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[4345] at textFile at <console>:221\n"},"dateCreated":"Apr 17, 2016 7:59:46 PM","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:30"},{"text":"//data.collect()","dateUpdated":"Apr 17, 2016 7:59:46 PM","config":{"colWidth":12,"editorMode":"ace/mode/scala","graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1460937586540_482846526","id":"20160417-195946_1870207895","result":{"code":"SUCCESS","type":"TEXT","msg":"res66: Array[String] = Array(AKM1MP6P0OYPR-0132793040 Dic|29 WC|40 achieve|0 adverb|2 affect|2 anger|0 anx|0 article|2 assent|0 auxverb|2 bio|0 body|0 cause|0 certain|1 cogmech|7 conj|2 death|0 discrep|2 excl|4 family|0 feel|0 filler|0 friend|0 funct|18 future|0 health|0 hear|0 home|0 humans|1 i|0 incl|0 ingest|0 inhib|0 insight|1 ipron|1 jeopardy|17 leisure|2 money|3 motion|0 negate|0 negative|1 negemo|0 nonfl|0 number|0 past|0 percept|0 posemo|2 positive|2 ppron|2 preps|6 present|3 pronoun|3 quant|1 relativ|1 relig|0 sad|0 satiq|0 see|0 sexual|0 shehe|0 social|4 space|1 swear|0 tentat|1 they|0 time|0 verb|3 we|0 wine|11 work|1 you|2 rating|5.0, A2CX7LUOHB2NDG-0321732944 Dic|99 WC|126 achieve|5 adverb|7 affect|6 anger|2 anx|1 article|7 assent|0 auxverb|8 bio|0 body|0 cause|1 certain|4 ..."},"dateCreated":"Apr 17, 2016 7:59:46 PM","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:31"},{"text":"val parsedData = data.map { line =>\nval parts = line.split(\" \")\nLabeledPoint(parts(72).split(\"\"\"\\|\"\"\")(1).toDouble, Vectors.dense(parts.slice(3,71).map(x => x.split(\"\"\"\\|\"\"\")(1).toDouble).toArray))\n}\n","dateUpdated":"Apr 17, 2016 7:59:46 PM","config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1460937586540_482846526","id":"20160417-195946_996838199","result":{"code":"SUCCESS","type":"TEXT","msg":"parsedData: org.apache.spark.rdd.RDD[org.apache.spark.mllib.regression.LabeledPoint] = MapPartitionsRDD[2089] at map at <console>:219\n"},"dateCreated":"Apr 17, 2016 7:59:46 PM","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:32"},{"text":"//parsedData.collect()\n//PCA\nval pca = new PCA(68).fit(parsedData.map(_.features))\nval projected = parsedData.map(p => p.copy(features = pca.transform(p.features)))","dateUpdated":"Apr 17, 2016 7:59:46 PM","config":{"colWidth":12,"editorMode":"ace/mode/scala","graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1460937586540_482846526","id":"20160417-195946_1139978353","result":{"code":"SUCCESS","type":"TEXT","msg":"pca: org.apache.spark.mllib.feature.PCAModel = org.apache.spark.mllib.feature.PCAModel@164185d2\nprojected: org.apache.spark.rdd.RDD[org.apache.spark.mllib.regression.LabeledPoint] = MapPartitionsRDD[2093] at map at <console>:223\n"},"dateCreated":"Apr 17, 2016 7:59:46 PM","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:33"},{"text":"val splits = projected.randomSplit(Array(0.8, 0.2), seed = 11L)\n\tval training = splits(0).cache()\n\tval test = splits(1).cache()","dateUpdated":"Apr 17, 2016 7:59:46 PM","config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1460937586540_482846526","id":"20160417-195946_219795352","result":{"code":"SUCCESS","type":"TEXT","msg":"splits: Array[org.apache.spark.rdd.RDD[org.apache.spark.mllib.regression.LabeledPoint]] = Array(MapPartitionsRDD[3114] at randomSplit at <console>:225, MapPartitionsRDD[3115] at randomSplit at <console>:225)\ntraining: org.apache.spark.rdd.RDD[org.apache.spark.mllib.regression.LabeledPoint] = MapPartitionsRDD[3114] at randomSplit at <console>:225\ntest: org.apache.spark.rdd.RDD[org.apache.spark.mllib.regression.LabeledPoint] = MapPartitionsRDD[3115] at randomSplit at <console>:225\n"},"dateCreated":"Apr 17, 2016 7:59:46 PM","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:34"},{"text":"%md Start with Linear Regression pipeline","dateUpdated":"Apr 19, 2016 8:14:57 PM","config":{"colWidth":12,"editorMode":"ace/mode/markdown","graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1460937586540_482846526","id":"20160417-195946_714852367","result":{"code":"SUCCESS","type":"HTML","msg":"<p>Start with Linear Regression pipeline</p>\n"},"dateCreated":"Apr 17, 2016 7:59:46 PM","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:35","dateFinished":"Apr 19, 2016 8:14:59 PM","dateStarted":"Apr 19, 2016 8:14:57 PM","focus":true},{"text":"//Linear regression\r\n\tval lr = new LinearRegression()\r\n\tlr.setMaxIter(10)\r\n\tlr.setRegParam(0.01)\r\n\r\n\t//Pipeline \r\n\tval pipeline = new Pipeline().setStages(Array(lr))\r\n\t\r\n\t//Cross validation\r\n\tval crossval = new CrossValidator()\r\n\tcrossval.setEstimator(pipeline)\r\n\tcrossval.setEvaluator(new RegressionEvaluator)\r\n\r\n\t//Parameter grid builder\r\n\tval paramGrid = new ParamGridBuilder()\r\n\tparamGrid.addGrid(lr.regParam, Array(0.1, 0.01))\r\n\tparamGrid.addGrid(lr.maxIter, Array(5, 10, 20))\r\n\tparamGrid.addGrid(lr.tol, Array(.00001,.001, .0001))\r\n\tval arrayMap = paramGrid.build()\r\n\tcrossval.setEstimatorParamMaps(arrayMap)\r\n\tcrossval.setNumFolds(4)\r\n\r\n\tval cvModel = crossval.fit(training.toDF)\r\n\t\r\n\t// Training Data Prediction & Score\r\n\tval trainPredictions = cvModel.transform(training.toDF()).select(\"prediction\", \"label\")\r\n\tval trainPredictionsAndLabels = trainPredictions.map {case Row(p: Double, l: Double) => (p, l)}\t\r\n\t\r\n\t// Get Training metrics\r\n\tval trainingMetrics = new RegressionMetrics(trainPredictionsAndLabels)\r\n\tprintln(\"\\nRoot Mean Squared Error = \" + trainingMetrics.rootMeanSquaredError)\r\n\r\n\t// Test Data Prediction & Score\r\n\tval testPredictions = cvModel.transform(test.toDF()).select(\"prediction\", \"label\")\r\n\tval testPredictionsAndLabels = testlabelAndPreds.map {case Row(p: Double, l: Double) => (p, l)}\r\n\r\n\t// Get Test Metrics\r\n\tval testMetrics = new RegressionMetrics(testPredictionsAndLabels)\r\n\tprintln(\"Root Mean Squared Error : \" + testMetrics.rootMeanSquaredError)\r\n\r\n","dateUpdated":"Apr 17, 2016 8:17:18 PM","config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1460937586540_482846526","id":"20160417-195946_1346827346","dateCreated":"Apr 17, 2016 7:59:46 PM","dateStarted":"Apr 17, 2016 8:17:18 PM","dateFinished":"Apr 17, 2016 8:18:25 PM","status":"ERROR","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:36"},{"config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1460937683673_569753805","id":"20160417-200123_1793868276","dateCreated":"Apr 17, 2016 8:01:23 PM","status":"READY","progressUpdateIntervalMs":500,"$$hashKey":"object:37"}],"name":"Zepplin-ML-PipeLine","id":"2BHX9J5UK","angularObjects":{"2BG8BPDP9":[],"2BHNAV395":[],"2BGSFZYEE":[],"2BJX6426Q":[],"2BFSKPM5X":[],"2BJKHGQ3R":[],"2BHZQM1U7":[],"2BFX6W7GN":[],"2BJP5JC8X":[],"2BFZMKZSA":[],"2BH8UF92D":[],"2BG97XDQR":[],"2BHS1DUDZ":[],"2BJ1GKVSW":[]},"config":{"looknfeel":"default"},"info":{}}